# HyperLogLog(HLL)

考虑一个问题：如何统计在单日内访问某个网站的唯一用户数量。对于只有少量访问者的小网站来说这很简单，但在处理拥有数十亿用户的大型网站时，这个问题会变得复杂得多。在这种情况下，将每个用户存储在列表中并检查重复项是不切实际的。海量数据会引发诸多挑战，包括内存耗尽、处理时间缓慢以及其他低效问题。

### 1. 要解决什么问题？—— 基数统计

首先，明确 HLL 要解决的问题：**海量数据下的基数统计**。

所谓基数（Cardinality），就是一个集合中​**​不重复元素​**​的个数。例如，集合 `{1, 3, 5, 3, 1}` 的基数是 3。

传统方法（如使用 HashSet）的瓶颈在于，它们需要存储所有唯一的元素。当数据量达到亿级甚至万亿级时（例如统计 Google 一天内不重复的搜索关键词、大型网站的独立访客数 UV），这种内存开销是无法承受的。

HyperLogLog 的精妙之处在于：**它可以用极小的内存空间（通常只需几 KB）来估算巨量数据的基数，并且将误差率控制在很低的范围内（如 1% - 2%）。**

------

### 2. 核心思想：用概率来估算

HLL 不是一个精确算法，而是一个**概率估算算法**。它的核心思想可以用一句话概括：

**通过观测数据集中随机事件发生的概率，来反推数据集的规模。**

这个“随机事件”就是：**一个均匀分布的哈希值，其二进制表示中前导零的数量。**

------

### 3. 直观的例子：抛硬币

想象一下你在抛硬币（正反面概率各为50%），你连续抛，直到抛出**正面（1）**为止。记录下第一次出现正面时，你总共抛了多少次。

- 如果你第一次就抛出了正面（序列：`1`），我们记 `leading_zeros = 0`。（或者说，第一个就是1，前面没有0）
- 如果你抛出了反反正（序列：`0, 0, 1`），我们记 `leading_zeros = 2`。
- 序列 `0, 0, 0, 0, 0, 1` 则有 `leading_zeros = 5`。

显然，第一次出现正面所需的次数（或前导零的数量+1）是一个随机变量。**出现需要抛很多次才见到正面的情况（即前导零很多）是很少见的**。

现在，假设你告诉我你做了这么一组实验，在这个实验中，你看到的**最长前导零序列是 `k`**。我就可以据此估算你总共做了多少次实验（即抛了多少次硬币，也就是“基数”）。

- 如果你说最长序列是 `1`（即第一次就是正面），我猜你大概只抛了 2~3 次。
- 如果你说最长序列是 `5`，我敢肯定你肯定抛了非常非常多次，大概 $$2^5=32$$ 次左右。

这就是 HLL 最根本的直觉。**一个很高的前导零数量，意味着我们看到了一个很低概率的事件，而低概率事件的发生，暗示着背后有一个很大的数据集（很多次抛硬币实验）。**

数学上，估算的公式是 $$\hat{n} = 2^k$$，其中 `k` 是观测到的最大前导零数量。

------

### 4. HyperLogLog 的具体实现

将上面的直觉工程化，就得到了 HyperLogLog 算法。

#### 步骤 1: 哈希化

将所有输入元素通过一个**哈希函数**处理，生成一个长度固定（例如 64 位）的二进制串。这个哈希函数必须是均匀分布的，这样输出才像是“随机的硬币抛掷”。

- 输入：`element_i` (例如一个用户ID)
- 输出：`hash_value` (一个 64 位的 0/1 序列，例如 `001101...`)

#### 步骤 2: 分桶（Register）

为了降低估算结果的方差，提高准确性，HLL 引入了**分桶平均**的策略。

1. **决定分桶数 `m`**： 通常取 `m = 2^b`，例如 `b=14`，那么 `m=16384` 个桶。桶的数量决定了内存的使用量和精度。
2. **确定桶下标**： 取哈希值的前 `b` 位（如上例，前14位），将其转换为一个十进制数，这个值就是桶的索引 `index`。 例如，哈希值前14位是 `00 1101 1010 0101` (二进制)，换算成十进制是 `12325`，那么这个元素就被分配到第 `12325` 个桶。
3. **计算“尾随”的零**： 对于剩下的 (`64 - b`) 位二进制串（我们称之为 `尾串`），计算从第一位开始**连续出现零的个数（直到遇到第一个1为止）**，我们把这个数记为 `ρ` (rho)。注意，这里计算的是“尾串”的前导零，但原理和之前说的“抛硬币”完全一样。 例如，尾串是 `000...1...`，前导零有3个，则 `ρ = 3`。 如果尾串是 `1...`，则 `ρ = 0`。

#### 步骤 3: 更新寄存器

每个桶（寄存器）只存储一个值：**当前该桶遇到的最大 `ρ` 值**。
 当一个新元素到来时：

1. 计算它的哈希值。
2. 根据前 `b` 位找到对应的桶 `j`。
3. 计算其尾串的 `ρ`。
4. 如果当前 `ρ > register[j]`，则令 `register[j] = ρ`；否则什么都不做。

#### 步骤 4: 计算估算值

当需要获取基数估计值时，对所有桶的值进行**调和平均**，然后乘以一个修正因子。

1. 计算所有桶的调和平均值：
    $$Z=\frac{m}{\sum_{j=1}^m2^{-register[j]}}$$
2. 估算值：
    $$\hat{n}=\alpha_m\cdot m\cdot Z$$

其中，$$\alpha_m$$ 是一个修正因子，用于修正系统偏差。当 m≥16 时，其值可以近似计算或查表得到（例如，m=16 时，$$\alpha_{16}$$≈0.673；m=32 时，$$\alpha_{32}$$≈0.697）。

#### 步骤 5: 修正特殊情况

最后，算法还会对估算结果进行一些修正，例如：

- 如果估算值很小，而某些桶的值是0，说明可能还没有充分利用所有桶，可能会采用线性计数（Linear Counting）法。
- 如果估算值非常大（接近 $$2^{32}$$），则会对结果进行修正以防止偏差。

经过这些步骤，就得到了最终的基数估计值。

------

### 总结与特点

| 特性             | 描述                                                         |
| :--------------- | :----------------------------------------------------------- |
| **内存效率极高** | 通常只需要几 KB 内存。例如，使用 16K (16384) 个桶，每个桶最大存 `ρ`（因为尾串长度固定，`ρ` 最大值也是固定的，通常用 4~6 bit 就够了），总内存约为 `16384 * 6 bit ≈ 12 KB`。这可以估算最高近 264 的基数！ |
| **非精确算法**   | 它是一个估算器，提供的是带有误差的近似值。标准误差率约为 $$1.04/\sqrt{m}$$。使用 16K 个桶时，误差率约为 `1.04 / 128 ≈ 0.8%`。 |
| **可合并性**     | 非常适合分布式系统。多个 HLL  sketch 可以很容易地合并：只需对每个桶取两个来源中的最大值即可。这使得它可以用于 MapReduce 或 Spark/FLink 等流处理系统。 |

总而言之，HyperLogLog 通过哈希将元素转化为随机数，利用“小概率事件揭示大基数”的概率原理，并通过分桶平均的策略来降低方差，最终用极小的内存开销实现了对海量数据基数的精准估算。